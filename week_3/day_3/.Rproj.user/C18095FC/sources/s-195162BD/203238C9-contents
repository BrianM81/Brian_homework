---
title: "Cleaning data"
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    df_print: paged
    css: ../../../styles.css
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = 'center')
library(tidyverse)
```


# Learning objectives

* Understand the importance of cleaning data before any analysis
* Know the common errors that crop up
* Be able to deal with common errors (apart from outliers and missing values - covered next)


# Data Cleaning 

It is said that the average data analyst spends about 80% of their time cleaning their data. That's a long time! And it highlights how important it is to understand data cleaning. Today's lessons will teach you how to do some important data cleaning in R. 

<br>
<center>
![](http://blog.appliedinformaticsinc.com/wp-content/uploads/2015/08/Screen-Shot-2015-08-13-at-4.43.50-PM-225x300.png)
</center>
<br>


Exactly what data cleaning entails depends a lot on what the data you’ve got looks like, and what you’re trying to do with it. But often, you’ll need to look through it to remove irrelevant or erroneous data points. You may need to create new variables, or join multiple data sets together to get what you need for your analysis. And you’ll also have to determine how to handle missing values, as very few real-world datasets are going to be 100% complete. You'll then have to get it into the right format, sort it, and summarise it. Lots of steps along the way!


In this first section, we will begin with the data cleaning you do as you load your data in, BEFORE you start looking at any odd values or analysing anything. The next sections will cover the more complex data cleaning issues of outliers and missing values are more complex to deal with. 


# Cleaning a simple dataset

For this initial lesson, we will be working with a sample dataset from the gaming company steam. The `video_game` dataset contains information on what games some Steam users bought and how many hours they spent playing them. 

This dataset is a list of user behaviors, with columns:   

*  `customer id`: player id    
*  `game name`: game name    
*  `what`: what activity were they playing   
*  `value`: hours of game play   
*  `bought online`: 1 if the user bought the game online, and a 0 if they didn't.  

[You can find the full dataset here](https://www.kaggle.com/tamber/steam-video-games/downloads/steam-video-games.zip/3)



# Removing Metadata

Metadata is data about data. Often this will be listed in an accompanying file. However, sometimes you'll find that there is metadata within the data file as well, and you don't want it to be there. In our example dataset, there are 4 rows at the top, which just describe what the data is, and when it was last modified. 

<br>
<center>
![](images/metadata.png)
</center>
<br>

What happens when you try and load this? 


```{r, eval = FALSE}
# load in the csv file without removing metadata
video_games <- read_csv("data/steam-200k-sample.csv")

```
<br>
You get an error...   
`Error in make.names(x) : invalid multibyte string at '<b4><8e><e8>"<44>ata Source"'`  
<br>

This is because it can't read the metadata at the top. The solution here is too add the `skip` option into your `read_csv` call, and this will allow you to remove the metadata at the top. 


```{r}
# load in the video games data, and remove the metadata 
video_games <- read_csv("data/steam-200k-sample.csv", skip = 4)
```



# Checking variable types

We mentioned yesterday that a warning that can come up a lot is that your data has been read in a certain way. If we look at the output above, we see that:

  * `customer_id` column has been read in as a `double`  
  * `game_name` column has been read in as `character`  
  * `what` column has been read in as `character`  
  * `value` column has been read in as `double`  
  * `bought online` column has been read in as `double`  
  
  
What does this all mean?  


## Double vs. integer

Numeric vectors can either be of type `double` or type `integer`. A `double` is any decimal number, while an `integer` is any whole number (positive or negative). By default all numbers are considered to be of type `double`, unless you put an "L" afterwards. This tells R to treat that number as an `integer`. 

```{r}
# double
dble <- c(1, 4, 6, 3)
class(dble)

# integer
intgr <- c(1L, 4L, 6L, 3L)
class(intgr)
```


## Character vs. factor

R also has two different types of text vector. A `character` vector is a plain text vector. 

```{r}
c("a", "a", "b", "a")
```

Factors are very similar, except R keeps track of each "level" of the vector and won't let you add new ones. You can change a character vector to factor via the `as.factor()` function. Factors can be **ordered**. Once a factor is ordered then you can do comparisons on it. If you don't specify the order of the levels, R will order them in alphabetical order by default. 

```{r}
as.factor(c("a", "a", "b", "a"))
```

## Logical

The last type of vector you will see is a vector filled with `TRUE` or `FALSE` values. These are known as `logical` vectors, and `TRUE` and `FALSE` are boolean values. Note that there are no quotes around `TRUE` and `FALSE`. 

```{r}
c(TRUE, TRUE, TRUE, TRUE, FALSE, FALSE)
```


## Summary

Below is a summary with examples of the five vector types we've covered

| Type | Example | Description |
|---|---|---|
| Double   | `c(2.2, 0.1, 5)` | Each element is always a number. |
| Integer   | `c(2L, 16L, 8L)` | Special character "L" indicates an `integer` value. |
| Character | `c("apple", "pear", "e")` | Each element can be anything with quotes around it. |
| Factor | `as.factor(c("apple", "pear", "e"))` | Similar to a character vector. | 
| Logical   | `c(TRUE, FALSE, FALSE)` | Each element is either `TRUE` or `FALSE`. |
<br>

You can use the `class()` function to check the type of a vector.

*Numeric Double*

```{r}
x <- 2.456
class(x)
```

*Numeric Integer*

```{r}
x <- 2L
class(x)
```

*Character*

```{r}
x <- "hello world"
class(x)
```

*Factor*

```{r}
x <- factor("hello world")
class(x)
```

*Logical*

```{r}
x <- TRUE
class(x)
```


# Loading in data as correct variable types

Now we know a bit more about the different variable types, we can check how R is loading our data in. 

```{r}

video_games <- read_csv("data/steam-200k-sample.csv", skip = 4)

```

If we look at our data dictionary, we see that the variable `bought online` should be a `logical`, and so we should change this as we load it in.   


```{r}
video_games <- read_csv("data/steam-200k-sample.csv", skip = 4, col_types = cols( 'bought online' = col_logical() ))

video_games
```

Ok great, we now know we've got the right data coming in!


# Adding and fixing variable names

In an ideal world, you'll recieve data that is properly labelled. However in the real world, this isn't always the case. Let's look at what variable names we have in our dataset.   

```{r}
names(video_games)
```


<blockquote class = 'task'>
**Task - 2 minutes**

Think back to our best practice lesson from yesterday. Why are these variable names not ideal?

<details>
<summary>**Answer**</summary>

First and foremost, the names don't really explain what is in each column. Secondly, there are spaces within the column headers, which we don't want. 

</details>
</blockquote>
<br>


We can fix these names up using the `clean_names()` function from the package `janitor`. This converts the variable names into usable names. First, lets install and load the package.  



```{r, warning = FALSE, message = FALSE}
library(janitor)

```

Now, we can use it to clean up our names.  


```{r}
# now let's use the clean_names() function
video_games_clean <- clean_names(video_games)

names(video_games_clean)
```

What's the difference? 

The other way we can do this is by just renaming the variables ourselves.    

```{r}

# add column names
names(video_games) <- c("customer_id", "game_title", "activity", "playing_hours", "bought_online") 
names(video_games)
```


<blockquote class='task'>
**Task - 5 mins** 

Note the difference between the two approaches. What are the differences? Which method do you think is best for renaming column names?

<details>
<summary>**Answer**</summary>

Both have their benefits and downsides.   

For the first method, the benefit is that it is quick and harder to make errors. The downside is that you don't have control over the naming like you do if you rename everything manually. 

For the second method, the benefit is you have total control over what you are naming the columns. However, this method only really works effectively if you have few variables. There is also the danger that you'll miss out a column and rename a column incorrectly.   

</details>
</blockquote>


# Checking string variables 

Another common problem you will come across in data is string consistency. That is, when you have character variables, which represent categories, it is important that they are all coded the same. For example, let's look at the games **Assassin's Creed II** and **Left 4 Dead 2**.   

```{r}
video_games_clean %>%
  select(game_name) %>%
  filter(game_name %in% c("Assassin's Creed II", "Left 4 Dead 2", "assassin's creed II", "left 4 dead 2"))
```

Here you can see that we have the same game, listed with different case letters. One way of dealing with this is to make your string data all lowercase or uppercase. This is known as 'defensive' programming - if you code in to always make string variables one case, then your code will usually run with conditional statements set. 

```{r}

# set strings to upcase across all
video_games_upcase <- mutate_all(video_games, 
                                 .funs=toupper)
head(video_games_upcase)

# set a column (but this probably isn't what we want right now)
library(stringr)
video_games_lowcase <- video_games_upcase %>%
  mutate(game_title = str_to_lower(game_title))



```

Great. Now we know that if we end up summarising the data by categories, there won't be any case issues. 


# Removing useless columns 

The final common issue we will cover is redundant columns. Sometimes you receive variables which don't contain any useful data. For example, in our dataset we have the `activity` variable, which contains the entry `play`. 

We can check whether the column contains only one value by using the `distinct` function. 

```{r}
# check for unique values in what we think is a redundant column
video_games_upcase %>%
  distinct(activity)
```

In this case, we have only one value in the activity column, and it isn't really adding anything to the data. So let's drop it.   


```{r}
# remove the activity column 
video_games_less <- video_games_upcase %>% 
  select(-activity)
head(video_games_less)
```


And there we go. We've covered the initial data cleaning process! Next, we will learn more about outliers and missing data points! 





