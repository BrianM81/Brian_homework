---
title: "R Notebook"
output: html_notebook
---

---
title: "Day 2 Homework"
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: false
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = 'center')
library(tidyverse)
```



# Homework

The data we're going to use for this homework comes from a data bank of facial recognition data ratings. In this dataset, people were shown faces and asked to rated different characteristics about them. People were free to respond however they wanted, and data was collected from many different people. You can start to imagine that the incoming dataset might be a little messy... Your task is to read in the input csv file, and use the verbs you have learned today to get it into a workable dataset for analysis. 

<br>

# Question 1

Let's start by loading the tidyverse library and reading the data in. You learned earlier this week how to get a feel for your data when you first load it in. Find out the dimensions, variable names, and print the first 10 rows. 

```{r}
library(tidyverse) #Loading tidyverse
library(readr)
face_descriptions <- read_csv("face_descriptions.csv")
```

#Look at dimensions of data
```{r}
dim(face_descriptions)
```

#Look at column names
```{r}
colnames(face_descriptions)
```

#Look at row names
```{r}
rownames(face_descriptions)
```

#Print out first 10 rows of dataset
```{r}
head(face_descriptions, 10)
```

# Question 2

Do these variable names look tidy to you? What format is your data in (long or wide)? 
The variable names do ot look tidy, often they are numbers or alphanumeric values, not very descriptive.

This table does not look tidy due to the folllowing
1 There are some missing values, such as 'NA' or '?'
2 The entries in the dataset are often duplicated in other tables, suggesting there is unneccessary data present.

The format of the data is wide (220 columns by 53 names)


# Question 3

Being faced with such complex data can be daunting, we may feel overwhelmed and ask ourselves:

* How can I organise this data?
* How can I make this data meaningful?
* How can I make this data tidy?

The first problem you can always tackle is to get your data in an appropriate format. What format do you need?

Once you have figured that out, reshape the data into the appropriate format. 


**Hint**
Use the `pivot_longer()` function to gather the data into long format. You'll need to put all columns beginning with t into one column. 

Answer = although the data is in a long format already, it is still not very readable as there are > 50 columns. I want the table to be "thinner" so it is easier to see at a glance eveything we need.

```{r}
# tidy the descriptions data
face_descriptions_long <- face_descriptions %>%
  pivot_longer(cols = starts_with("t"), 
               names_to = "description", 
               values_to = "observations")

# view the data, first 10 for comparison
 head(face_descriptions_long, 10)
```


# Question 4

But wait! Some people have given lengthy descriptions of the faces, some have only given one word. This can be problematic for analysis, if you eventually want to summarise key descriptions. 

Some people have split the description of the faces using a slash. Use the separate function to split apart the descriptions column so that if people have given more than one answer (i.e. if the data is separated by a /) it is moved into a new row. 

First, you'll need to decide a cut off for how many responses you want to accept from people. Is one enough? Two? Three? Once you've decided how many descriptions you want to code, you'll have to separate your description columns into that many columns. 

Answer
```{r}
# split the codes and descriptions column 
face_descriptions_long_sep <- face_descriptions_long %>%
  separate(observations, c("first observation", "second observation", "third observation"), sep = "\\ ")

head(face_descriptions_long_sep, 10) #Not sure why this isn't working now, it was working earlier?!
```



# Question 5

We've now split the data, and have three description variables. But is this data ACTUALLY tidy? Isn't one of the rules that we need to have only one column per variable? And now we have more than one description variables... 

What do we need to do here so our description variables follow the rules of tidy data?

**Hint**
Use the `pivot_longer()` function to create a new description column, which will identify which description number it is (1,2,3, etc), and to create one single variable called `description` which contains the actual description. Save it all in a new tibble called `all_descriptions`.

```{r}
# tidy the description data
all_descriptions <- face_descriptions_long_sep%>%
  pivot_longer(cols = ends_with("observation"),
           names_to = "main_observation",
          values_to = "result")      
            
# view the data 
head(all_descriptions, 10) #Unexpected reault below
```


# tidy the hospital data
hospital_visits_long <- hospital_visits %>%
  pivot_longer(cols = starts_with("FY"), 
               names_to = "year", 
               values_to = "visit_numbers")

# view the data 
head(hospital_visits_long)


# Question 6

But, wait... another problem arises... not everyone provided three descriptions! So, if you look at the data, we have some missing values (NAs). We also have some nonsense descriptions (e.g. “f” and “.”). Let's now sort these out. 

Use the `filter` function to get rid of NA's and useless descriptions.


**Hint**
Hint: look back at the previous sections where we dealt with null values (i.e. the `is.na()` function. If you want to keep everything that is not equal to NA, what would you need to do? If you wanted to make sure you kept everything where the `description` variable had more than one character, is there a function you could use? This is a task extension - you haven't used this function before, but try googling for a function that counts the **number of characters** in a variable. You can then use a logical operator (which we also learned about this week), to ensure you only select where there is more than 1 character present. 


# Question 7

Now we can actually find something out about our data. Let's find out what the most common description of each face is. Earlier in the week you learnt how to pipe functions together to create summary stats. 

Group the data by `description`, and summarise the data by generating a count for each group.   



# Question 8

Finally, arrange the output so that we have the most common description at the top, and the least common at the bottom.  

**Hint** 
Do you need ascending or descending order for this?
Create a tibble called `top_10_descriptions`, which filters your arranged data so that it only takes the top 10 answers.   

This will help us answer the question: what are the most common descriptions of faces given?




# Question 9

So from that messy dataset, we now have a nice summary table of the 10 most common descriptions of faces. And we did it quickly! But one of the most useful things we learnt this week was how to create a pipe. Try your hand at changing the code above into a pipe. Start from the very beginning, where you load in the data. Save it all in a tibble called `faces`. 


